[0m[[0m[31merror[0m] [0m[0morg.apache.flink.runtime.client.JobExecutionException: Job execution failed.[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.jobmaster.JobResult.toJobExecutionResult(JobResult.java:144)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.minicluster.MiniClusterJobClient.lambda$getJobExecutionResult$3(MiniClusterJobClient.java:141)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:642)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2073)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.lambda$invokeRpc$1(AkkaInvocationHandler.java:268)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:859)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:837)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2073)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.util.concurrent.FutureUtils.doForward(FutureUtils.java:1277)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.lambda$null$1(ClassLoadingUtils.java:93)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.lambda$guardCompletionWithContextClassLoader$2(ClassLoadingUtils.java:92)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:859)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:837)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2073)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.concurrent.akka.AkkaFutureUtils$1.onComplete(AkkaFutureUtils.java:47)[0m
[0m[[0m[31merror[0m] [0m[0m	at akka.dispatch.OnComplete.internal(Future.scala:300)[0m
[0m[[0m[31merror[0m] [0m[0m	at akka.dispatch.OnComplete.internal(Future.scala:297)[0m
[0m[[0m[31merror[0m] [0m[0m	at akka.dispatch.japi$CallbackBridge.apply(Future.scala:224)[0m
[0m[[0m[31merror[0m] [0m[0m	at akka.dispatch.japi$CallbackBridge.apply(Future.scala:221)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.concurrent.akka.AkkaFutureUtils$DirectExecutionContext.execute(AkkaFutureUtils.java:65)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:68)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:284)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:284)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:284)[0m
[0m[[0m[31merror[0m] [0m[0m	at akka.pattern.PromiseActorRef.$bang(AskSupport.scala:621)[0m
[0m[[0m[31merror[0m] [0m[0m	at akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:24)[0m
[0m[[0m[31merror[0m] [0m[0m	at akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:23)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.concurrent.Future.$anonfun$andThen$1(Future.scala:532)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:29)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:29)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)[0m
[0m[[0m[31merror[0m] [0m[0m	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:63)[0m
[0m[[0m[31merror[0m] [0m[0m	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:100)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)[0m
[0m[[0m[31merror[0m] [0m[0m	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:100)[0m
[0m[[0m[31merror[0m] [0m[0m	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:49)[0m
[0m[[0m[31merror[0m] [0m[0m	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:48)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)[0m
[0m[[0m[31merror[0m] [0m[0mCaused by: org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:139)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:83)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:256)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:247)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:240)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:738)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:715)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:78)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:477)[0m
[0m[[0m[31merror[0m] [0m[0m	at jdk.internal.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.lang.reflect.Method.invoke(Method.java:566)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRpcInvocation$1(AkkaRpcActor.java:309)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:307)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:222)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:84)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)[0m
[0m[[0m[31merror[0m] [0m[0m	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)[0m
[0m[[0m[31merror[0m] [0m[0m	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)[0m
[0m[[0m[31merror[0m] [0m[0m	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)[0m
[0m[[0m[31merror[0m] [0m[0m	at akka.actor.Actor.aroundReceive(Actor.scala:537)[0m
[0m[[0m[31merror[0m] [0m[0m	at akka.actor.Actor.aroundReceive$(Actor.scala:535)[0m
[0m[[0m[31merror[0m] [0m[0m	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)[0m
[0m[[0m[31merror[0m] [0m[0m	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:580)[0m
[0m[[0m[31merror[0m] [0m[0m	at akka.actor.ActorCell.invoke(ActorCell.scala:548)[0m
[0m[[0m[31merror[0m] [0m[0m	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)[0m
[0m[[0m[31merror[0m] [0m[0m	at akka.dispatch.Mailbox.run(Mailbox.scala:231)[0m
[0m[[0m[31merror[0m] [0m[0m	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)[0m
[0m[[0m[31merror[0m] [0m[0mCaused by: java.io.IOException: Failed to deserialize consumer record due to[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:143)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:385)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:542)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:831)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:780)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:935)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:914)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:728)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:550)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.lang.Thread.run(Thread.java:834)[0m
[0m[[0m[31merror[0m] [0m[0mCaused by: org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException: Could not forward element to next operator[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:99)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:57)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:29)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.tasks.SourceOperatorStreamTask$AsyncDataOutputToOutput.emitRecord(SourceOperatorStreamTask.java:313)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.api.operators.source.SourceOutputWithWatermarks.collect(SourceOutputWithWatermarks.java:110)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter$SourceOutputWrapper.collect(KafkaRecordEmitter.java:67)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:84)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaValueOnlyDeserializationSchemaWrapper.deserialize(KafkaValueOnlyDeserializationSchemaWrapper.java:51)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:143)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:385)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:542)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:831)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:780)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:935)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:914)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:728)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:550)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.lang.Thread.run(Thread.java:834)[0m
[0m[[0m[31merror[0m] [0m[0mCaused by: com.datastax.spark.connector.datasource.CassandraCatalogException: Attempting to write to C* Table but missing[0m
[0m[[0m[31merror[0m] [0m[0mprimary key columns: [sensor_id][0m
[0m[[0m[31merror[0m] [0m[0m	at com.datastax.spark.connector.datasource.CassandraWriteBuilder.<init>(CassandraWriteBuilder.scala:44)[0m
[0m[[0m[31merror[0m] [0m[0m	at com.datastax.spark.connector.datasource.CassandraTable.newWriteBuilder(CassandraTable.scala:69)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.v2.BatchWriteHelper.newWriteBuilder(WriteToDataSourceV2Exec.scala:346)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.v2.BatchWriteHelper.newWriteBuilder$(WriteToDataSourceV2Exec.scala:341)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec.newWriteBuilder(WriteToDataSourceV2Exec.scala:273)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec.run(WriteToDataSourceV2Exec.scala:284)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:39)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:39)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.doExecute(V2CommandExec.scala:54)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:122)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:121)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:944)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:944)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:342)[0m
[0m[[0m[31merror[0m] [0m[0m	at main$.$anonfun$stream1$1(Main.scala:94)[0m
[0m[[0m[31merror[0m] [0m[0m	at main$.$anonfun$stream1$1$adapted(Main.scala:81)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.api.scala.DataStream$$anon$4.map(DataStream.scala:629)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:38)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:82)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:57)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:29)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.tasks.SourceOperatorStreamTask$AsyncDataOutputToOutput.emitRecord(SourceOperatorStreamTask.java:313)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.api.operators.source.SourceOutputWithWatermarks.collect(SourceOutputWithWatermarks.java:110)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter$SourceOutputWrapper.collect(KafkaRecordEmitter.java:67)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:84)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaValueOnlyDeserializationSchemaWrapper.deserialize(KafkaValueOnlyDeserializationSchemaWrapper.java:51)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:143)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:385)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:542)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:831)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:780)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:935)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:914)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:728)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:550)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.lang.Thread.run(Thread.java:834)[0m
[0m[[0m[31merror[0m] [0m[0m(Compile / [31mrun[0m) org.apache.flink.runtime.client.JobExecutionException: Job execution failed.[0m
